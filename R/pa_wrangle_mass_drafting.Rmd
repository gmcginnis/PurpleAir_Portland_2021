---
title: "pa_wrangle_mass_drafting"
author: "Gillian McGinnis"
date: "1/12/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #dplyr, ggplot2, etc
library(lubridate) #better time/date manipulation
library(viridis) #better color scales
library(ggthemes) #better themes
#library(janitor) #used for clean_names function
```


```{r data}
my_file_paths <- list.files(path = "data/raw", pattern = ".+\\(*(outside*)\\w+\\)", full.names = TRUE)

#my_file_paths <- list.files(path="data/raw", pattern=".+(E )",full.names=TRUE) #smaller subset
#my_file_paths <- list.files(path="data/raw", pattern="SE",full.names=TRUE) #smaller subset

raw_data <- my_file_paths %>%
  set_names() %>%
  map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
                                         created_at = col_character(),
                                         .default = col_double())), .id="source") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name
```


```{r again}
#do not run this often. large dataframes!
my_file_paths <- list.files(path = "data/raw", pattern = ") Primary Real Time", full.names = TRUE)

#my_file_paths <- list.files(path="data/raw", pattern=".+(E )",full.names=TRUE) #smaller subset
#my_file_paths <- list.files(path="data/raw", pattern="SE",full.names=TRUE) #smaller subset
#my_file_paths <- list.files(path="data/raw", pattern="(STAR).+Primary",full.names=TRUE)

#pray that R doesn't crash when you run this
raw_data <- my_file_paths %>%
  set_names() %>%
  map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
                                         created_at = col_character(),
                                         UptimeMinutes = col_skip(),
                                         X11 = col_skip(),
                                         .default = col_double())), .id="source") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name
```

```{r}
reading <- function(filepath){
  temp_data <- filepath %>%
    set_names() %>%
    read_csv(col_types = cols(created_at = col_character(),
                                         `PM2.5_ATM_ug/m3` = col_double(),
                                         .default = col_skip())) %>%
    mutate(source = filepath,
           source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name
}

path <- list.files(path="data/raw",pattern="SE ",full.names=TRUE)

reading(path)

all_csv <- lapply(path,read_csv())

#Set the name of each list element to its
# respective file name. Note full.names = FALSE to
# get only the file names, not the full path.
names(all_csv) <- gsub(".csv","",
                       list.files("path/to/files",full.names = FALSE),
                       fixed = TRUE)
```



```{r file paths}
all_paths <- list.files(path="data/raw", pattern="SE ",full.names=TRUE)
# *.csv
# Primary Real Time

raw_data <- all_paths %>%
  set_names() %>%
  map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
                                         created_at = col_character(),
                                         .default = col_double())), .id="source") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name

processing <- function(file_path){
  
}
```

```{r}
## Create a list of the files
all_paths <- list.files(path="data/raw", pattern="SE ",full.names=TRUE)

## Pre-allocate a list to store all of the results of reading
## so that we aren't re-copying the list for each iteration
DTList <- vector(mode = "list", length = length(FileList))

## Read in all the files, excluding the first two columns
# for(i %in% seq_along(DTList)) {
#   DTList[[i]] <- data.table::fread(all_paths[[i]], drop = c(1,2))
# }

## Combine the results into a single data.table
DT <- data.table::rbindlist(DTList)

## Optionally, convert the data.table to a data.frame to match requested result
## Though I would recommend looking into using data.table instead!
data.table::setDF(DT)


# my_data <- lapply(all_paths, 
#                   read.csv, 
#                   header=TRUE,
#                   sep="\t")

all_paths <- list.files(path="data/raw", pattern=") Primary Real Time",full.names=TRUE)


my_file_paths <- list.files(path="data/raw", pattern="(STAR).+Primary",full.names=TRUE)

# raw_data <- all_paths %>%
#   set_names() %>%
#   map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
#                                          created_at = col_character(),
#                                          `PM2.5_ATM_ug/m3` = col_double(),
#                                          .default = col_skip())),
#           .id="source") %>%
#   mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name


raw_data <- my_file_paths %>%
  set_names() %>%
  map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
                                         created_at = col_character(),
                                         `PM2.5_ATM_ug/m3` = col_double(),
                                         .default = col_skip())), .id="source") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name


# filenames <- list.files(path="data/raw", pattern="SE ",full.names=TRUE)
# 
# ##Create list of data frame names without the ".csv" part 
# #names <- substr(filenames,1,7)
# names <- str_replace(filenames, ".\\w+\\/\\w+\\/", "")
# 
# ###Load all files
# for(i in names){
#     filepath <- file.path("data/raw",paste(i,".csv",sep=""))
#     assign(i, read.delim(filepath,
#     colClasses=c("character","factor",rep("numeric",4)),
#     sep = "\t"))
# }
# 
myfiles <- list.files(pattern = ".csv") # create a list of all csv files in the directory
data_csv <- map_dfr(all_paths,
                    #~data.table::fread(.x, drop = c(3:10,12:23), colClasses=c(created_at="character"))) %>%
                    ~data.table::fread(.x,
                                       colClasses=c(source="character",
                                                    created_at="character",
                                                    .default=NULL))) %>%
  as.data.frame()



```




```{r tidying}

df <- raw_data %>%
  #drop_na(`PM2.5_CF1_ug/m3`) %>% #removes empty values for stat of interest
  mutate(created_at = as_datetime(created_at), #converting from character to date time format; tz is in UTC
         date = date(created_at), #picking out just the date
         #time = strftime(created_at, format="%H:%M:%S"), # old way of picking time; outputs char
         time = hms::as_hms(created_at), #picking out just the time
         time_est = time) %>% #currently working on rounding out the seconds but for now it stands as is
  mutate(coords = str_extract(source, "([0-9])\\w+\\.([0-9])\\w+\\s\\-([0-9])\\w+\\.([0-9])\\w+"), #grabbing coord data
         lat = str_extract(coords, "\\d+\\.\\d+\\s"), #latitude (north)
         lat = str_trim(lat, side = "right"), #removing extra whitespace
         lat = as.numeric(lat), #converting to numeric from character
         long = str_extract(coords, "\\-\\d+\\.\\d+"), #longitude (negative here, so west)
         long = as.numeric(long), #converting to numeric from character
         loc_tag = str_extract(source, "^[^\\(]+"), #grabbing location tag
         loc_tag = str_trim(loc_tag, side = "right")) %>% #removing extra whitespace
  mutate(hour = hour(created_at),
         hour_round = hour(round_date(created_at, unit="hour")),
         year = year(created_at),
         month = month(created_at, label=TRUE),
         day = day(created_at))


unique_locations <- unique(df$loc_tag) #creates list of unique locations for quick reference
unique_vars <- names(df) #creates list of columns for quick reference
```

```{r summary dfs}
vars <- names(df)[4:20]

daily_df_all <- df %>%
  group_by(loc_tag, date, lat, long) %>%
  summarize_at(vars,
               mean,
               na.rm=TRUE)

hourly_df_all <- df %>%
  group_by(loc_tag, date, hour, lat, long) %>%
  summarize_at(vars,
               mean,
               na.rm=TRUE)
```

```{r pm25 dfs, echo=FALSE}
hourly_df_pm25 <- df %>%
  drop_na(`PM2.5_CF1_ug/m3`) %>% #removes empty values for stat of interest
  filter(`PM2.5_CF1_ug/m3` <= 1000) %>%
  group_by(loc_tag, date, hour, lat, long) %>%
  summarize(mean_pm25 = mean(`PM2.5_CF1_ug/m3`),
            sd_pm25 = sd(`PM2.5_CF1_ug/m3`)) %>%
  mutate(month=month(date,label=TRUE),
         day=day(date))

daily_df_pm25 <- df %>%
  drop_na(`PM2.5_CF1_ug/m3`) %>% #removes empty values for stat of interest
  #filter(`PM2.5_CF1_ug/m3` <= 1000) %>%
  group_by(loc_tag, date, lat, long) %>%
  summarize(mean_pm25 = mean(`PM2.5_CF1_ug/m3`),
            sd_pm25 = sd(`PM2.5_CF1_ug/m3`)) %>%
  mutate(month=month(date,label=TRUE),
         day=day(date))
```



```{r hourly25 viz}
hourly_viz_pm25 <- ggplot(hourly_df, aes(x=date, y=mean_pm25, color=loc_tag))+
  #geom_line(alpha=0.7)+
  geom_point(alpha=0.7,shape=4)+
  theme(legend.position="none")+
  labs(title="Raw PM2.5, averaged hourly, colored by sensor")

hourly_viz_pm25
```


```{r daily25 viz}
daily_viz_pm25 <- ggplot(daily_df, aes(x = date, y = mean_pm25, color = loc_tag))+
  #geom_line(alpha=0.7)+
  geom_point(alpha=0.7,shape=4)+
  theme(legend.position="none")+
  labs(title="Raw PM2.5, averaged daily, colored by sensor")

daily_viz_pm25
```

```{r daily heatmap}
daily_mini <- daily_df %>%
  filter(str_detect(loc_tag, "STAR"))

#ggplot(data=subset(mini_set, month%in%c("Oct","Nov")), aes(x=day, y=0, fill=mean_pm25))+
ggplot(daily_mini, aes(x=day, y=0, fill=mean_pm25))+
  geom_tile()+
  scale_fill_viridis(name = "Daily PM25", option = "plasma")+
  facet_grid(loc_tag~month)+
  scale_x_continuous(breaks = c(1,10,20,31))+
  theme_minimal(base_size=8)+
  labs(title = paste("Daily PM25"), x= "Day", y="")+
  theme(legend.position="bottom",
        #legend.position="bottom",
        plot.title=element_text(size=14, hjust = 0),
        #axis.text.y=element_text(size=6),
        axis.text.y=element_blank(),
        strip.background = element_rect(colour="white"),
        axis.ticks=element_blank(),
        axis.text=element_text(size=7),
        #legend.title=element_text(size=8),
        #legend.text=element_text(size=6),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

```{r hourly heatmap}
# Source: https://www.r-graph-gallery.com/283-the-hourly-heatmap.html
hour_mini <- hourly_df %>%
  filter(str_detect(loc_tag, "STAR"))

hourly_heatmap_pm25_STAR <- ggplot(hour_mini, aes(x=day, y=hour, fill=mean_pm25))+
#ggplot(subset(hour_mini, month%in%c("Oct","Nov")), aes(day, hour, fill = mean_pm25))+
  #geom_tile(color = "white", size=0.1)+
  geom_tile()+
  scale_fill_viridis(name = "Hrly PM25", option = "plasma")+
  facet_grid(loc_tag~month)+
  scale_y_continuous(trans = "reverse", breaks = unique(df$hour))+
  scale_x_continuous(breaks = c(1,10,20,31))+
  theme_minimal(base_size=8)+
  labs(title = paste("Hourly PM25"), x= "Day", y = "Hour commencing")+
  theme(legend.position="bottom",
        plot.title=element_text(size=14, hjust = 0),
        axis.text.y=element_text(size=6),
        strip.background = element_rect(colour="white"),
        axis.ticks=element_blank(),
        axis.text=element_text(size=7),
        legend.title=element_text(size=8),
        legend.text=element_text(size=6),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank())

hourly_heatmap_pm25_STAR

#flip flop
# ggplot(data=subset(df, month%in%c("Sep","Oct","Nov")), aes(hour, day, fill = `PM2.5_CF1_ug/m3`))+
#   #geom_tile(color = "white", size=0.1)+
#   geom_tile()+
#   scale_fill_viridis(name = "Hrly PM25", option = "plasma")+
#   facet_grid(month~loc_tag)+
#   scale_x_continuous(trans = "reverse", breaks = unique(df$hour))+
#   scale_y_continuous(breaks = c(1,10,20,31))+
#   theme_minimal(base_size=8)+
#   labs(title = paste("Hourly PM25"), y= "Day", x = "Hour commencing")+
#   theme(legend.position="bottom",
#         plot.title=element_text(size=14, hjust = 0),
#         axis.text.x=element_text(size=6),
#         strip.background = element_rect(colour="white"),
#         axis.ticks=element_blank(),
#         axis.text=element_text(size=7),
#         legend.title=element_text(size=8),
#         legend.text=element_text(size=6),
#         panel.grid.major = element_blank(), panel.grid.minor = element_blank())
```

```{r saving dfs}
#write.csv(raw_data, "data/wrangled/raw_df.csv", row.names=TRUE)
write.csv(df, "data/wrangled/wrangled_df.csv", row.names=TRUE)

write.csv(hourly_df,"data/wrangled/hourly_df.csv", row.names = TRUE)
write.csv(daily_df, "data/wrangled/daily_df.csv", row.names=TRUE)
```


```{r saving viz}
ggsave("hourly_viz_pm25.png", plot=hourly_viz_pm25, path="figures/")
ggsave("daily_viz_pm25.png", plot=daily_viz_pm25, path="figures/")

ggsave("hourly_heatmap_pm25_STAR.png", plot=hourly_heatmap_pm25_STAR, path="figures/")
```

```{r ab grab}
#my_file_paths <- list.files(path="data/raw", pattern="SE",full.names=TRUE) #smaller subset
all_paths <- list.files(path="data/raw", pattern="Real Time",full.names=TRUE)

my_files <- all_paths %>%
  as.data.frame() %>%
  rename(source = ".") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) %>% #removes filepath name
  mutate(loc_tag = str_extract(source, "^[^\\(]+"),
         #loc_tag_new = str_replace(loc_tag, " B ", ""),
         #inoutun = str_extract(source, "(outside|inside|undefined)"),
         inout = str_extract(source, "(outside|inside)"),
         ab = str_extract(source, " B \\("),
         primsec = str_extract(source, "\\) (Primary|Secondary)")) %>%
  mutate(loc_tag = str_replace(loc_tag, " B ", ""),
         loc_tag = str_trim(loc_tag, side="right"),
         primsec = str_extract(primsec, "(Primary|Secondary)"),
         ab = str_extract(ab, "B"),
         ab = replace_na(ab, "A")) %>%
  group_by(loc_tag) %>%
  #select(loc_tag_new, inout, ab) %>%
  fill(inout) %>%
  filter(inout == "outside",
         primsec == "Primary") %>%
  select(!c(inout, primsec))
```

```{r ab comp new}
var_names <- names(wrangled_data)[13:22]
a_vars <- paste(names(wrangled_data)[13:22],"_A",sep="")
b_vars <- paste(names(wrangled_data)[13:22],"_B",sep="")

wrangled_mini <- wrangled_data %>%
  filter(str_detect(loc_tag, "SE "))

ab_comp_func <- function(df, var_input){
  a <- paste(var_input,"_A",sep="")
  b <- paste(var_input,"_B",sep="")
  
  df$var_input %>%
    mutate(var_input = ((a-b)/a)*100)
}

ab_comp_new <- wrangled_mini %>%
  group_by(loc_tag, inout, ab, date, hour, min) %>%
  summarise_at(all_of(var_names), mean) %>%
  pivot_wider(names_from=ab, values_from=all_of(var_names)) %>%
  group_by(loc_tag, inout, date, hour, min) %>%
  mutate(
    
  )
  mutate(
    var_names = (((a_vars-b_vars)/a_vars)*100)
  )
  

ab_comp_func(ab_comp_new, var_names)

ab_comp_del <- wrangled_mini %>%
  group_by(loc_tag, inout, ab, date, hour, min) %>%
  summarise_at(all_of(var_names), mean)

ab_comp_per <- function(df, var_input){
  a <- df %>% filter(ab=="A")
  b <- df %>% filter(ab=="B")
  new_lab <- paste(var_input,"_delta",sep="")
  
  df <- df %>% mutate(new_lab = ((a-b)/a)*100)
}

ab_comp_per(ab_comp_del, var_names)
```


```{r loc data, eval=FALSE}

loc_data <- data %>%
  distinct(source) %>%
  #mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) %>% #removes filepath name
  mutate(loc_tag = str_extract(source, "^[^\\(]+"),
         loc_tag = str_replace(loc_tag, " B ", ""),
         loc_tag = str_trim(loc_tag, side="right")) %>%
         #loc_tag_new = str_replace(loc_tag, " B ", ""),
         #inoutun = str_extract(source, "(outside|inside|undefined)"),
  mutate(inout = str_extract(source, "(outside|inside)")) %>%
  group_by(loc_tag) %>%
  #select(loc_tag_new, inout, ab) %>%
  fill(inout) %>%
  mutate(coords = str_extract(source, "([0-9])\\w+\\.([0-9])\\w+\\s\\-([0-9])\\w+\\.([0-9])\\w+"), #grabbing coord data
         lat = str_extract(coords, "\\d+\\.\\d+\\s"), #latitude (north)
         lat = str_trim(lat, side = "right"), #removing extra whitespace
         lat = as.numeric(lat), #converting to numeric from character
         long = str_extract(coords, "\\-\\d+\\.\\d+"), #longitude (negative here, so west)
         long = as.numeric(long)) %>%
  select(!c(source, coords)) %>%
  distinct(loc_tag, .keep_all=TRUE)
  
```

```{r ab comp}
#var_of_interest <- "PM2.5_ATM_ug/m3"
ab_comp <- data %>%
  select(source, created_at, `PM2.5_ATM_ug/m3`) %>% #var of interest
  drop_na(`PM2.5_ATM_ug/m3`) %>% #var of interest
  mutate(loc_tag = str_extract(source, "^[^\\(]+"),
         loc_tag = str_replace(loc_tag, " B ", ""),
         loc_tag = str_trim(loc_tag, side="right"),
         ab = str_extract(source, " B \\("),
         ab = str_extract(ab, "B"),
         ab = replace_na(ab, "A")) %>%
  select(!c(source)) %>%
  mutate(created_at = as_datetime(created_at), #converting from character to date time format; tz is in UTC
         date = date(created_at), #picking out just the date
         time = hms::as_hms(created_at)) %>% #picking out just the time
    mutate(hour = hour(created_at),
           min = minute(created_at),
         month = month(created_at, label=TRUE),
         day = day(created_at)) %>%
  group_by(loc_tag, ab, date, hour, min) %>%
  summarize(mean_pm25 = mean(`PM2.5_ATM_ug/m3`)) %>% #var_of_interest
  ungroup() %>%
  pivot_wider(names_from = ab, values_from=mean_pm25) %>%
  mutate(per_change = ((A-B)/A)*100) %>%
  select(loc_tag, per_change) %>%
  mutate(per_change_check = case_when((per_change < 100 & per_change > -100) ~ per_change)) %>%
  drop_na(per_change_check) %>%
  select(loc_tag, per_change) %>%
  #drop_na(per_change) %>%
  group_by(loc_tag) %>%
  summarize(mean_per = mean(per_change))

# ab_comp_filtered <- ab_comp %>%
#   mutate(reliable = case_when((mean_per <= 15 & mean_per >= -15) ~ TRUE)) %>%
#   drop_na(reliable) %>%
#   select(!c(reliable))
```


```{r ab and loc}
sensor_info <- loc_data %>%
  full_join(ab_comp)
#write.csv(sensor_info, "data/wrangled_new/sensor_info.csv", row.names=TRUE)
```


```{r ab comp 2, eval = FALSE}
data_subset <- wrangled_data %>%
  filter(str_detect(loc_tag, "STAR"))

vars <- names(data_subset)[13:22]
a_vars <- paste(names(data_subset)[13:22],"_A",sep="")
b_vars <- paste(names(data_subset)[13:22],"_B",sep="")
delta_vars <- paste(names(data_subset)[13:22],"_delta",sep="")
mean_vars <- paste(names(data_subset)[13:22],"_mean",sep="")


ab_subset_test <- data_subset %>%
  #group_by(loc_tag, inout, ab, date, hour, min) %>%
  group_by(loc_tag, inout, ab, date, hour) %>%
  summarise_at(all_of(vars), mean) %>%
  #group_by(loc_tag, inout, ab, date, hour) %>%
  #summarise_at(all_of(vars), )
  #summarize(mean()) %>%
  pivot_wider(names_from=ab, values_from=all_of(vars)) %>%
  group_by(loc_tag, inout, date, hour)
  #mutate_at(vars(matches(vars)), diff)
  #summarize_at(all_of(a_vars), delta)

# del <- function(var) {
#   
# }

library(quantmod)

ab_subset_quantmod <- data_subset %>%
  group_by(loc_tag, inout, ab, date, hour) %>%
  summarize_at(all_of(vars), mean) %>%
  group_by(loc_tag, inout, date, hour) %>%
  summarize_at(all_of(vars), Delt)

ab_mini <- ab_subset_quantmod %>%
  #summarize_at(all_of(vars), na.rm=TRUE)
  group_by(loc_tag, inout) %>%
  summarize_at(all_of(vars), mean, na.rm = TRUE)

ab_subset_4 <- data_subset %>%
  group_by(loc_tag, inout, ab, date, hour) %>%
  #summarise_at(all_of(vars), list(mean=mean, diff=diff)) %>%
  summarise_at(all_of(vars), mean) %>%
  group_by(loc_tag, inout, date, hour)%>%
  summarise_at(all_of(vars), list(mean=mean, diff=diff))
  # group_by(loc_tag, inout, ab, date, hour) %>%
  # summarise_at(all_of(vars), list(mean=mean, diff=diff))

# ab_subset_2 <- ab_subset_test %>%
#   group_by(loc_tag, inout, date, hour) %>%
#   summarise_at(all_of(vars), mean) %>%
#   mutate_at(a_vars, a_vars-b_vars) %>%
#   mutate(delta_vars = a_vars-b_vars)

#pct <- function(x){x / lag(x) - 1}
#pct <- function(x){}
#df_vertical_growth %>% group_by(YEAR, VERTICAL) %>% mutate_at(funs=pct,Profit)
#FUN=function(x) c(NA,diff(x)))
# delta <- function(input){
#   ((paste(input,"_A") - paste(input,"_B",sep="")) / (paste(input,"_A"))*100)
# }
# 
# delta_ab <- function(input){
#   a <- . %>% filter(ab=="A") %>% select(input)
#   b <- . %>% filter(ab=="B") %>% select(input)
#   #b <- $input %>% filter(ab=="B")
#   ((a-b)/a)*100
# }

ab_subset_3 <- data_subset %>%
  group_by(loc_tag, inout, ab, date, hour) %>%
  #summarize_at(all_of(vars), delta_ab)
  summarize_at(all_of(vars), mean) %>%
  mutate(difference = )
  group_by(loc_tag, inout, date, hour) %>%
  summarize_at(all_of(vars), diff)
  #summarize_at(all_of(vars), diff)
  #summarize_at(all_of(vars), .funs=sum) %>%
  #mutate(delta = ave(all_of(vars), factor(df$ab), FUN=function(x) c(NA,diff(x))))
```