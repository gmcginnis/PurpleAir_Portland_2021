---
title: "api_testing"
author: "Gillian McGinnis"
date: "6/10/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(knitr)
library(rmarkdown)
library(lubridate)
#devtools::install_github("MazamaScience/AirSensor")

library(tidyverse)
library(AirSensor)
```

```{r mini_test, eval = FALSE}
pat_createNew(
  label = "Seattle", 
  pas = example_pas, 
  startdate = 20180701, 
  enddate = 20180901
)
```

```{r setting_archive_dir}
path.expand("~")

#archiveDir <- "~/data/airsensor_archive"
archiveDir <- file.path(path.expand("~"), "PurpleAir_Portland_2021/data/airsensor_archive")
```

```{r find_sensors}
# Set the archiveBaseUrl so we can get a 'pas' object
setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")

# Load the default 'pas' (today for the entire US)
pas <- pas_load()

# Subset by state
or <- pas_filter(pas, stateCode == "OR")

# Look at it
pas_leaflet(or)
```

```{r}
pdx <- pas_filterArea(pas = or, w = -122.854, e = -122.58, s = 45.4, n = 45.6)

pas_leaflet(pdx)
```

```{r}

dir.create(archiveDir, recursive = TRUE)

setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")

pas_leaflet(pdx)

save(pdx, file = file.path(archiveDir, "pdx.rda"))

# Examine archive directory:
list.files(file.path(archiveDir))


pdx_ids <- pas_getDeviceDeploymentIDs(pdx)

#startdate <- "2020-09-01"
#enddate <- "2020-11-30"
startdate <- "2020-07-01"
enddate <- "2020-07-08"
timezone <- "America/Los_Angeles"

patList <- list()

idCount <- length(pdx_ids)
count <- 0 
successCount <- 0

for (id in pdx_ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # Here we show the full function signature so you can see all possible arguments
    patList[[id]] <- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = pdx,
      startdate = startdate,
      enddate = enddate,
      timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
  
}

print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

save(patList, file = file.path(archiveDir, "patList.rda"))

sapply(patList, function(x) { return(x$meta$label) })
print(object.size(patList), units = "MB")
fileSize <- file.size(file.path(archiveDir, "patList.rda"))
sprintf("%.1f Mb", fileSize/1e6)
```



```{r}
rm(list = setdiff(ls(), c("archiveDir")))

# Examine archive directory:
list.files(file.path(archiveDir))
```

```{r}
pdx <- get(load(file.path(archiveDir, "pdx.rda"))) 
patList <- get(load(file.path(archiveDir, "patList.rda")))

psu <- patList[["a20209a9fb613315_3775"]]
lc <- patList[["387c47b51f2c6811_26477"]]

pat_multiplot(lc)

pat_dygraph(lc)
pat_outliers(lc)
pat_internalFit(lc)
pat_dailySoHPlot(lc)
```

```{r}
#pas_staticMap(pdx, paletteName = "RdPu", mapTheme = "toner-lite", zoomAdjust = 1)
```


```{r}
star_labels <- pas_getLabels(pas = pdx, pattern = "STAR")
```


```{r, eval = FALSE}
# patList[[2]]$meta
# 
# pat_extractMeta(patList[[2]])
# 
# meta_df <- data.frame()
# data_df <- data.frame()
# 
# for(i in patList){
#   df_temp <- pat_extractMeta(patList[[i]])
#   
#   meta_df <- rbind(meta_df, df_temp)
# }

patList[[1]]$data %>% 
  select(datetime, pm25_A, pm25_B, pm25_atm_A, pm25_atm_B, temperature, humidity) %>% 
  mutate(date = date(datetime)) %>% 
  select(!datetime) %>% 
  group_by(date) %>% 
  summarize_at(vars(!date), mean, na.rm = TRUE)

map_dfr(patList[1], patList[2])

#unnest(patList[[2]]$data, cols = c(datetime, pm25_A, pm25_B, pm25_atm_A, pm25_atm_B, temperature, humidity))
patList_transposed <- transpose(patList)

patList_transposed[[1]] %>% reduce(inner_join)

sites_meta <- bind_rows(patList_transposed[[1]], .id = "site_id")
sites_data <- bind_rows(patList_transposed[[2]], .id = "site_id")
```


```{r iteration_old,eval=FALSE}
# Setup for iteration
patList <- list()
idCount <- length(ids)
count <- 0 
successCount <- 0

# Iteration
for (id in ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case we get "no data" errors
  result <- try({
    
    patList[[id]] <- pat_createNew(
      id = id,
      label = NULL,   # Label not needed since we have the IDs
      pas = pas_area,
      startdate = input_startdate,
      enddate = input_enddate,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
  
}

# Review
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))
```

```{r cleaning_environment,eval=FALSE}
remove(input_startdate, input_enddate, idCount, count, successCount, ids, id, result)
```

```{r transpose_data,eval=FALSE}
# patList_transposed <- transpose(patList)
# raw_meta <- bind_rows(patList_transposed[[1]], .id = "site_id")
# raw_data <- bind_rows(patList_transposed[[2]], .id = "site_id")

patList_transposed <- pmap(patList, bind_rows, .id = "site_id")
raw_meta <- patList_transposed[[1]]
raw_data <- patList_transposed[[2]]

# Cleaning environment
remove(patList_transposed)
```

```{r, imrpoved_loading, eval=FALSE}
# Setup for iteration
idCount <- length(ids)
count <- 0 
successCount <- 0

pat_single <- list()
raw_meta <- data.frame()
data_a <- data.frame()
data_b <- data.frame()

# Iteration
for (id in ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  ####
  pat_single <- pat_downloadParseRawData(
    id = id,
    label = NULL,   # Label not needed since we have the IDs
    pas = pas_area,
    startdate = input_startdate,
    enddate = input_enddate,
    baseUrl = "https://api.thingspeak.com/channels/"
  )
  
  raw_meta_single <- pat_single$meta %>% 
    mutate("site_id" = id) %>% 
    drop_na(DEVICE_LOCATIONTYPE)
  
  raw_meta <- rbind(raw_meta, raw_meta_single)
  
  data_a_single <- pat_single$A_PRIMARY %>% 
    select(c(created_at, pm2.5_cf1, pm2.5_atm, temperature, humidity)) %>% 
    rename(
      pm25_cf1_A = pm2.5_cf1,
      pm25_atm_A = pm2.5_atm
    ) %>% 
    mutate("site_id" = id)
  
  data_a <- rbind(data_a, data_a_single)
  
  data_b_single <- pat_single$B_PRIMARY %>%
    select(c(created_at, pm2.5_cf1, pm2.5_atm)) %>% 
    rename(
      pm25_cf1_B = pm2.5_cf1,
      pm25_atm_B = pm2.5_atm
    ) %>% 
    mutate("site_id" = id)
  
  data_b <- rbind(data_b, data_b_single)
  ####
  successCount <- successCount + 1
  
  remove(data_a_single, data_b_single, raw_meta_single, pat_single)
}

raw_data <- data_a %>% 
      full_join(data_b) %>% 
      mutate(datetime = floor_date(created_at, unit = "2 minutes")) %>% 
      group_by(site_id, datetime) %>% 
      summarize_if(is.numeric, mean, na.rm = TRUE)

# Review
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))
```
