---
title: "summer_api_scripting"
author: "Gillian McGinnis"
date: "6/23/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(AirSensor)
library(lubridate)
library(ggmap)
library(viridis)
```

```{r fixing_qmplot, eval = FALSE}
detach("package:ggmap")
remove.packages("ggmap")

devtools::install_github("dkahle/ggmap")

.rs.restartR()
library(ggmap)
```


```{r inputs}
# Boundaries (in degrees) of monitors to include
n <- 45.6
e <- -122.58
s <- 45.4
w <- -122.854

# Optional: State of monitors to include. Default: NULL
# If NULL, all monitors specified in the above boundaries will be included regardless of state
state_code <- "OR"

# Start and end dates
startdate <- "2020-09-01"
enddate <- "2020-09-30"

# Grab data from outdoor and/or indoor sensors
include_outside <- TRUE
include_inside <- TRUE

# Run date grouping?
run_dategrouping <- TRUE
# Date grouping categories
if(run_dategrouping == TRUE){
  dategroup_tags <- c("Before", "Fire", "After")
  dategroup_starts <- c("2020-09-01", "2020-09-10", "2020-09-20")
  dategroup_ends <- c("2020-09-09", "2020-09-19", "2020-09-30")
} else {
  print("Date grouping will not occur.")
}

# Run hour grouping?
run_hourgrouping <- TRUE
# Hour grouping categories
if(run_hourgrouping == TRUE){
  hourgroup_tags <- c("Morning", "Afternoon", "Evening", "Night")
  hourgroup_starts <- c(5, 12, 17, 21)
} else {
  print("Hour grouping will not occur.")
}
```

```{r getting_pas}
get_area_pas <- function(state_code = NULL, w, e, s, n, datestamp = enddate){
  setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")
  pas <- pas_load(
    archival = TRUE,
    datestamp = str_replace_all(as.character(datestamp), "-", "")
  )
  if(is.null(state_code) == TRUE){
    pas_state <- pas
  } else {
    pas_state <- pas_filter(pas, stateCode == state_code)
  }
  pas_area <- pas_filterArea(pas = pas_state, w = w, e = e, s = s, n = n)
  return(pas_area)
}

pas_area <- get_area_pas(state_code = state_code, w = w, e = e, s = s, n = n)

# Cleaning environment
remove(get_area_pas, state_code, n, e, s, w)
```

```{r getting_pat}
# Setup for iteration
ids_outside <- pas_getDeviceDeploymentIDs(pas_area, isOutside = TRUE)
ids_inside <- pas_getDeviceDeploymentIDs(pas_area, isOutside = FALSE)

if(include_outside == FALSE & include_inside == FALSE){
  inout_report <- ("INPUT ERROR: Please set `include_outside` and/or `include_inside` to TRUE.")
}
if(include_outside == TRUE & include_inside == TRUE){
  ids <- c(ids_outside, ids_inside)
  inout_report <- ("Both indoor and outdoor sensor data will be loaded.")
}
if(include_outside == TRUE & include_inside == FALSE){
  ids <- ids_outside
  inout_report <- ("Only outdoor sensor data will be loaded.")
}
if(include_outside == FALSE & include_inside == TRUE){
  ids <- ids_inside
  inout_report <- ("Only indoor sensor data will be loaded.")
}
print(inout_report)
remove(ids_outside, ids_inside, inout_report)

patList <- list()
#idCount <- length(pas_area)
idCount <- length(ids)
count <- 0 
successCount <- 0

# Iteration
for (id in ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case we get "no data" errors
  result <- try({
    
    patList[[id]] <- pat_createNew(
      id = id,
      label = NULL,        # Not needed if we have the ID
      pas = pas_area,
      startdate = startdate,
      enddate = enddate,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
  
}

# Review
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

# Cleaning environment
remove(startdate, enddate, idCount, count, successCount, ids, id, result)
```

```{r transpose_data}
patList_transposed <- transpose(patList)

raw_meta <- bind_rows(patList_transposed[[1]], .id = "site_id")
raw_data <- bind_rows(patList_transposed[[2]], .id = "site_id")

# Cleaning environment
remove(patList_transposed)
```

```{r timezone_function}
# Time zones are recorded when downloading data. Time stamps are reported in UTC. The following will convert the time stamps to said time zone.
# If more than one time zone is reported in the data, the conversion will use the time zone most frequently used in the data set. This is because no more than one time zone can be applied to a date time variable.
adjust_timezone <- function(dataset, location_data = raw_meta){
  if(length(unique(location_data$timezone)) > 1){
  print("Multiple time zones reported. Timestamp will be based on the most frequent time zone reported.")
  timezone <- (location_data %>% 
                 group_by(timezone) %>% 
                 count() %>% 
                 arrange(desc(n)) %>% 
                 pull(timezone))[1]
  } else {
    timezone <- unique(location_data$timezone)
  }
  print(paste("Time zone applied:", timezone))
  
  dataset_new <- dataset %>%
    rename(datetime_utc = datetime) %>% 
    mutate(datetime = with_tz(datetime_utc, tzone = timezone))
  
  return(dataset_new)
}
```

```{r qc_sets}
# Basic subsetting and quality control

data_meta <- raw_meta %>% 
  # Selecting only variables of interest, to save on storage
  select(site_id, DEVICE_LOCATIONTYPE, label, longitude, latitude, timezone)

data_pm25 <- raw_data %>% 
  # Selecting only variables of interest, to save on storage
  select(site_id, datetime, temperature, humidity, pm25_A, pm25_B, pm25_atm_A, pm25_atm_B) %>% 
  # Basic quality control; only possible values are kept
  # This will also drop missing values
  filter_at(
    # All columns that start with 'pm25'
    vars(starts_with("pm25")),
    # Filtering such that only values 0:2000 are kept
    any_vars(between(., 0, 2000))
  ) %>% 
  filter(
    # Filtering temperature for -40:185
    between(temperature, -40, 185),
    # Filtering humidity for 0:100
    between(humidity, 0, 100)
  ) %>% 
  # Adjusting to be reported time zone (see above function)
  adjust_timezone() %>% 
  # Creating variables for date and hour
  mutate(
    date = date(datetime),
    date_hour = floor_date(datetime, unit = "hour")
  ) %>% 
  select(site_id, datetime_utc, datetime, date, date_hour, everything())

# Cleaning environment
remove(adjust_timezone)
```

```{r corr_epa_factor}
apply_epa <- function(dataset, groupings){
  dataset %>% 
    group_by_at({{groupings}}) %>% 
    mutate(
      # Difference between A&B sensors
      diff = pm25_A-pm25_B,
      # Percentage difference between A&B sensors
      per_diff = 100*(abs(pm25_A-pm25_B))/((pm25_A+pm25_B)/2),
      drop = case_when(
        # We will drop the following based on EPA recommendations
        abs(diff) >= 5 & abs(per_diff) >= 62 ~ TRUE,
        # Fills all other values (the ones we'll keep) with false
        TRUE ~ FALSE
        )
      ) %>% 
    # Filtering out values which we have determined to drop
    filter(drop != TRUE) %>% 
    select(!c(drop, diff, per_diff)) %>% 
    group_by_at({{groupings}}) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    rowwise() %>% 
    mutate(
      # Averaging the A and B monitors
      pm25_cf1 = mean(c(pm25_A, pm25_B), na.rm = TRUE),
      # US-wide correction factor published in 2020
      epa_2020 = 0.524*pm25_cf1 - 0.0852*humidity + 5.72,
      # US-wide correction factor published in late 2020
      epa_2021 = case_when(
        pm25_cf1 <= 343 ~ 0.52*pm25_cf1 - 0.086*humidity + 5.75,
        pm25_cf1 > 343 ~ 0.46*pm25_cf1 + (3.93*10^(-4))*(pm25_cf1^2) +2.97
        )
      )
}

data_hourly_epa <- data_pm25 %>% 
  apply_epa(groupings = vars(site_id, date, date_hour))

# Filter all dates in which there are fewer than 18/24 hr worth of measurements
data_epa_drop <- data_pm25 %>% 
  group_by(site_id, date, date_hour) %>% 
  summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
  group_by(site_id, date) %>% 
  count() %>% 
  filter(n < 18)

data_daily_epa <- data_pm25 %>% 
  anti_join(data_epa_drop) %>% 
  apply_epa(groupings = vars(site_id, date))

# Cleaning environment
remove(apply_epa, data_epa_drop)
```

```{r lrapa}
apply_lrapa <- function(dataset, groupings){
  dataset %>% 
    group_by_at({{groupings}}) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    rowwise() %>% 
    mutate(
      pm25_cf1 = mean(c(pm25_A, pm25_B), na.rm = TRUE),
      pm25_atm = mean(c(pm25_atm_A, pm25_atm_B), na.rm = TRUE),
      lrapa = case_when(pm25_cf1 <= 65 ~ 0.5 * pm25_atm - 0.66)
      ) %>% 
    drop_na(lrapa)
}

data_hourly_lrapa <- data_pm25 %>% 
  apply_lrapa(groupings = vars(site_id, date, date_hour))

data_daily_lrapa <- data_pm25 %>% 
  apply_lrapa(groupings = vars(site_id, date))

# Cleaning environment
remove(apply_lrapa)
```

```{r group_sets}
data_daily <- data_daily_epa %>% 
  full_join(data_daily_lrapa)

data_hourly <- data_hourly_epa %>% 
  full_join(data_hourly_lrapa)

# Cleaning environment
remove(data_daily_lrapa, data_daily_epa, data_hourly_lrapa, data_hourly_epa)
```

```{r apply_dates_set}
apply_dates <- function(dataset,
                        starts = dategroup_starts, ends = dategroup_ends, tags = dategroup_tags,
                        date_stamp = "17 Jan 1999"){
  
  starts <- as.Date(starts)
  ends <- as.Date(ends)
  tags <- factor(tags)
  date_format <- stamp_date(date_stamp)
  
  data_temp <- data.frame(starts, ends, tags) %>% 
    arrange(starts) %>% 
    mutate(
      start_stamp = date_format(starts),
      end_stamp = date_format(ends),
      date_tag = fct_inorder(paste0(tags, " (", start_stamp, " to ", end_stamp, ")"))
    ) %>% 
    pivot_longer(cols = c(starts, ends), values_to = "date") %>% 
    group_by(date_tag) %>% 
    complete(date = full_seq(date, 1)) %>% 
    select(!c(name, tags, start_stamp, end_stamp))
  
  # data_temp <- data.frame(starts, ends, tags) %>% 
  #   arrange(starts) %>% 
  #   mutate(date_tag = fct_inorder(tags)) %>% 
  #   pivot_longer(cols = c(starts, ends), values_to = "date") %>% 
  #   group_by(date_tag) %>% 
  #   complete(date = full_seq(date, 1)) %>% 
  #   select(!c(name, tags))
  
  dataset %>% 
    left_join(data_temp) %>% 
    drop_na(date_tag)
}

if(run_dategrouping == TRUE){
  data_hourly <- apply_dates(data_hourly)
  data_daily <- apply_dates(data_daily)
  print("Data now grouped by provided date groupings.")
  remove(dategroup_starts, dategroup_ends, dategroup_tags)
} else {
  print("Date groups not applied.")
}

# Cleaning environment
remove(apply_dates, run_dategrouping)
```

```{r apply_hour_tags}
apply_hours <- function(dataset, starts = hourgroup_starts, tags = hourgroup_tags){
  tags <- factor(tags)
  
  hours_in_day <- data.frame(starts = 0:23)
  
  data_temp <- data.frame(starts, tags) %>% 
    mutate(
      ends = lead(starts - 1),
      ends = replace_na(ends, starts[1]-1),
      tags = paste0(tags, " (", formatC(starts, width=2, flag=0), ":00-", formatC(ends, width=2, flag=0), ":00)")
    ) %>% 
    arrange(starts) %>% 
    mutate(hour_tag = fct_inorder(tags)) %>%
    complete(starts = full_seq(starts, 1)) %>%
    right_join(hours_in_day) %>%
    rename(hour = starts) %>%
    fill(hour_tag) %>%
    select(!c(tags, ends))
  
  dataset %>% 
    mutate(hour = hour(date_hour)) %>% 
    left_join(data_temp)
}

if(run_hourgrouping == TRUE){
  data_hourly <- apply_hours(data_hourly)
  print("Data now grouped by provided hour groupings.")
  remove(hourgroup_starts, hourgroup_tags)
} else {
  print("Hour groups not applied.")
}

# Cleaning environment
remove(apply_hours, run_hourgrouping)
```


```{r map_function}
# FUNCTION
# Required inputs: pm_data (df), value (column of PM2.5 data w/in df to map), location_data (lat/long data to be joined to df; default: data_meta)
# Optional inputs: grouping variables (1 or 2) w/ respective custom exclusions; filter for indoor/outdoor data
# Other customization for map: type (stamen), zoom, tint & color, point size, color scale (virids)

map_q <- function(pm_data, value, location_data = data_meta,
                  grouping_var = NULL, exclude = NULL,
                  grouping_var_2 = NULL, exclude_2 = NULL,
                  outside = include_outside, inside = include_inside,
                  maptype = "toner-lite", zoom = 11, tint = 0.5, tint_color = "black",
                  point_size = 3, viridis = "viridis"){
  
  # Warning message and halting execution if required input is missing.
  if(missing(value) == TRUE) stop ("ERROR in argument 'value': Missing input, with no default. Execution haulted. Please input a valid PM2.5 variable (e.g. epa_2021).")
  
  # Wrangling based on provided inputs
  data_temp <- pm_data %>% 
    ungroup() %>% 
    group_by_at(vars(site_id, {{grouping_var}}, {{grouping_var_2}})) %>% 
    summarize(mean = mean({{value}}, na.rm = TRUE)) %>% 
    drop_na(mean) %>% 
    left_join(location_data)
  
  print("Data now grouped and averaged. Location data added.")
  
  # Custom filtering: exclusions for input categories
  if(is.null(exclude) == FALSE){
    to_exclude <- paste(exclude, collapse = "|")
    data_temp <- data_temp %>% 
      filter(!str_detect({{grouping_var}}, to_exclude))
    print(paste("Excluded", exclude, "from", deparse(substitute(grouping_var))))
  }
  if(is.null(exclude_2) == FALSE){
    to_exclude_2 <- paste(exclude_2, collapse = "|")
    data_temp <- data_temp %>% 
      filter(!str_detect({{grouping_var_2}}, to_exclude_2))
    print(paste("Excluded", exclude_2, "from", deparse(substitute(grouping_var_2))))
  }
  
  # Default shapes for inside/outside
  shapes_inout <- c("outside" = 21, "inside" = 23)
  
  # Custom filtering: exclusions for inside/outside
  # Will also override shape arguments to prevent excluded category from showing in the legend
  if(outside == FALSE){
    data_temp <- data_temp %>% 
      filter(DEVICE_LOCATIONTYPE != "outside")
    print("Excluded outdoor data")
    shapes_inout <- c("inside" = 23)
  }
  if(inside == FALSE){
    data_temp <- data_temp %>% 
      filter(DEVICE_LOCATIONTYPE != "inside")
    print("Excluded indoor data")
    shapes_inout <- c("outside" = 21)
  }
  
  
  # Labels for the plot
  lab_title <- expression("PM"[2.5]*" values")
  lab_subtitle <- paste("Data from PurpleAir. Data plotted:", deparse(substitute(value)))
  lab_pm <- expression(paste("Average PM"[2.5]*" (", mu, "g/m"^3*"):"))
  
  # Base plot
  plot <- qmplot(data = data_temp, x = longitude, y = latitude,
         geom = "blank", maptype = maptype, zoom = zoom, darken = c(tint, tint_color)) +
    facet_wrap(vars({{grouping_var}})) +
    geom_point(
      aes(fill = mean, shape = DEVICE_LOCATIONTYPE),
      color = "white",
      alpha = 0.8,
      size = point_size
    ) +
    scale_fill_viridis(
      option = {{viridis}},
      direction = -1,
      end = 0.85,
      limits = c(0, NA)
    ) +
    theme_void() +
    scale_shape_manual(values = shapes_inout) +
    theme(
      legend.position = "bottom",
      legend.box = "vertical"
    ) + 
    guides(shape = guide_legend(override.aes = list(fill="black"))) +
    labs(
      title = lab_title,
      subtitle = lab_subtitle,
      fill = lab_pm,
      shape = "Monitor location:",
      caption = "Data not grouped."
    )
  
  print("Base plot created.")
  
  ## Faceting by grouping variable(s) and applying an appropriate caption to reflect the grouping
  # Facet wrap if 1 grouping variable provided
  if(deparse(substitute(grouping_var)) != "NULL" &
     deparse(substitute(grouping_var_2)) == "NULL"
    ){
    plot <- plot +
      facet_wrap(vars({{grouping_var}})) +
      labs(
        caption = paste(
          "Data grouped by",
          (colnames(pm_data %>% select({{grouping_var}})))[1]
        )
      )
    print(paste("Plot now faceted by", deparse(substitute(grouping_var))))
  }
  # Facet grid if 2 grouping variables provided
  if(deparse(substitute(grouping_var)) != "NULL" &
     deparse(substitute(grouping_var_2)) != "NULL"
     ){
    plot <- plot +
      facet_grid(
      formula(paste(
        vars({{grouping_var_2}}),
        "~",
        vars({{grouping_var}})
      ))) +
      labs(
        caption = paste(
          "Data grouped by",
          deparse(substitute(grouping_var)),
          "and",
          deparse(substitute(grouping_var_2))
          )
      )
    print(paste("Plot now faceted by",
                deparse(substitute(grouping_var)),
                "and",
                deparse(substitute(grouping_var_2))
                ))
  }
  
  print("Final plot created.")
  
  # Returning the final plot
  plot
}
```

```{r map_tests, eval = FALSE}

map_q(data_hourly, value = epa_2021, grouping_var = hour_tag)

map_q(data_daily, value = epa_2020, grouping_var = date_tag, inside = FALSE)

map_q(data_daily, value = lrapa, grouping_var = date_tag, exclude = "Fire")

map_q(data_hourly, value = pm25_atm, grouping_var = hour_tag, exclude = "Afternoon", point_size = 5,
      maptype = "terrain", tint = 0.3, tint_color = "white", viridis = "magma")
```
