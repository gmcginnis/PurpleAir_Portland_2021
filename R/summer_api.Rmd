---
title: "summer_api"
author: "Gillian McGinnis"
date: "6/22/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(AirSensor)
library(lubridate)
```

```{r archive}
archiveDir <- file.path(getwd(), "data/airsensor_archive")
```

```{r getting_sensors}
get_local_pas <- function(stateCode = "OR", west = -122.854, east = -122.58, south = 45.4, north = 45.6){
  setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")
  pas <- pas_load()
  pas_state <- pas_filter(pas, stateCode == stateCode)
  pas_area <- pas_filterArea(pas = pas_state, w = west, e = east, s = south, n = north)
}

local_pas <- get_local_pas()
save(local_pas, file = file.path(archiveDir, "pdx.rda"))

remove(get_local_pas)
```

```{r}
#Setup
ids <- pas_getDeviceDeploymentIDs(local_pas)

startdate <- "2021-02-01"
enddate <- "2021-03-31"
#timezone <- "America/Los_Angeles"
#timezone <- unique(local_pas$timezone)

patList <- list()

idCount <- length(local_pas)
count <- 0 
successCount <- 0

# Iteration
for (id in ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # Here we show the full function signature so you can see all possible arguments
    patList[[id]] <- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = local_pas,
      startdate = startdate,
      enddate = enddate,
      #timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
  
}

# Review
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

save(patList, file = file.path(archiveDir, "patList.rda"))

remove(startdate, enddate, timezone, idCount, count, successCount, ids, id, result)
```

```{r transpose_data}
patList_transposed <- transpose(patList)

data_meta <- bind_rows(patList_transposed[[1]], .id = "site_id")
data_raw <- bind_rows(patList_transposed[[2]], .id = "site_id")

# Cleaning environment
remove(patList_transposed)
```

```{r shrink_sets}
data_meta

data_location <- data_meta %>% 
  select(site_id, label, longitude, latitude, timezone)

data_pm25 <- data_raw %>% 
  select(site_id, datetime, temperature, humidity, pm25_A, pm25_B, pm25_atm_A, pm25_atm_B)

data.frame(
  datetime = as_datetime(c("2020-03-05 08:02:12", "2020-03-05 08:01:04"), tz="UTC"),
  timezone = c("Poland", "Cuba")
) %>% 
  # group_by(timezone) %>% 
  rowwise() %>% 
  mutate(
    poland = with_tz(datetime, tzone = "Poland"),
    cuba = with_tz(datetime, tzone = "Cuba"),
    new = with_tz(datetime, tzone = timezone),
    format = format(new, usetz = TRUE)
    # #new = ymd_hms(datetime, tz = timezone),
    # with = with_tz(datetime, tzone = timezone),
    # alt = format(with, usetz = TRUE)
    )
```

```{r tz_adjusting}
raw_data %>% 
  select(datetime, temperature) %>% 
  mutate(
    datetime_new = with_tz(datetime, tzone = raw_meta$timezone[1])
  )

raw_data %>% 
  select(site_id, datetime, temperature) %>% 
  left_join(select(raw_meta, site_id, timezone)) %>% 
  rowwise %>% 
  mutate(
    datetime_new = with_tz(datetime, tzone = timezone)
  )
```


code before hour changes

```{r hour_testing, eval=FALSE}
#lims <- as.POSIXct(strptime(c("1970-01-01 00:00","1970-01-01 23:00"), format = "%Y-%m-%d %H:%M"))
starts <- input_hour_starts
tags <- factor(input_hour_tags)

hours_in_day <- data.frame(starts = 0:23)

new_hour <- data.frame(starts, tags) %>% 
  mutate(
    ends = lead(starts - 1),
    ends = replace_na(ends, starts[1]-1),
    tags = paste0(tags, "\n(", formatC(starts, width=2, flag=0), ":00-", formatC(ends, width=2, flag=0), ":59)")
  ) %>% 
  arrange(starts) %>% 
  mutate(hour_tag = fct_inorder(tags)) %>%
  complete(starts = full_seq(starts, 1)) %>%
  right_join(hours_in_day) %>%
  rename(hour = starts) %>%
  fill(hour_tag) %>%
  select(!c(tags, ends)) %>% 
  mutate(hour = hms::as_hms(hour*60*60))

dat %>% left_join(new_hour)

data_temp <- data.frame(starts, tags) %>% 
  mutate(
    ends = lead(starts - 1),
    ends = replace_na(ends, starts[1]-1),
    tags = paste0(tags, "\n(", formatC(starts, width=2, flag=0), ":00-", formatC(ends, width=2, flag=0), ":59)")
  ) %>% 
  arrange(starts) %>% 
  mutate(hour_tag = fct_inorder(tags)) %>%
  complete(starts = full_seq(starts, 1)) %>%
  right_join(hours_in_day) %>%
  rename(hour = starts) %>%
  fill(hour_tag) %>%
  select(!c(tags, ends))


dat <- raw_data %>% 
  filter(site_id==id) %>% 
  mutate(
    hr = hour(datetime),
    time = hms::as_hms(datetime),
    # sec_round = hms::round_hms(time, 60*60),
    # round = hms::as_hms(round(datetime, units  = "hours")),
    hour = hms::as_hms(hour(datetime)*60*60)
    # hour = as_datetime(hour)
    #hrrr = hms::round_hms(time, 60*60)
  ) %>% 
  group_by(hour) %>% 
  summarize(mean = mean(temperature, na.rm = TRUE))

lims <- c(min(dat$hour), max(dat$hour))

ggplot(dat, aes(x = hour, y = mean)) +
  geom_point() +
  scale_x_datetime(breaks = "1 hour",
    #breaks = scales::date_breaks("1 hour"),
                   date_labels = "%H:%M",
    #expand = c(0,0)
    expand = expansion(mult = c(0.01, 0.01))
                   #limits = lims
                   ) +
  theme(axis.text.x = element_text(angle = 30))
  #scale_x_time(breaks = scales::breaks_width("1 hour"))
  #scale_x_time(breaks = scales::breaks_width("1 hour"), labels = scales::label_time(format="%H:%M"))
```


```{r function_tz}
# Time zones are reported as a variable when downloading the data. Time stamps are reported in UTC. The following will convert the time stamps to said reported time zone.
# If more than one time zone is reported in the data, the conversion will use the time zone most frequently used in the data set. This is because no more than one time zone can be applied to a date time variable.
adjust_timezone <- function(dataset, location_data = raw_meta){
  
  # Translation: If more than 1 unique timezone is reported in the data frame, then:
  if(length(unique(location_data$timezone)) > 1){
  print("Multiple time zones reported. Timestamp will be based on the most frequent time zone reported.")
  timezone <- (location_data %>% 
                 group_by(timezone) %>% 
                 count() %>% 
                 arrange(desc(n)) %>% 
                 pull(timezone))[1]
  } else {
    timezone <- unique(location_data$timezone)
  }
  
  dataset_new <- dataset %>%
    # Original time stamps (in UTC) will be preserved
    rename(datetime_utc = datetime) %>% 
    # # Creating variables for date and hour
    # mutate(
    #   datetime = with_tz(datetime_utc, tzone = timezone),
    #   date = date(datetime),
    #   date_hour = floor_date(datetime, unit = "hour")
    # )
    # HR_TESTING
    mutate(
      datetime = with_tz(datetime_utc, tzone = timezone),
      date = date(datetime),
      time = hms::as_hms(datetime),
      date_hour = floor_date(datetime, unit = "hour"),
      hour = hms::as_hms(date_hour)
    )
  
  print(paste("Time zone applied:", timezone))
  return(dataset_new)
}
```

```{r function_qc}
apply_qc <- function(dataset, avg_ab = TRUE){
  
  # Creating columns to average A & B data
  if(avg_ab == TRUE){
    dataset <- dataset %>% 
      rowwise() %>% 
      mutate(
        pm25_cf1 = mean(c(pm25_cf1_A, pm25_cf1_B), na.rm = TRUE),
        pm25_atm = mean(c(pm25_atm_A, pm25_atm_B), na.rm = TRUE)
      ) %>% 
      ungroup()
    print("Columns for averages of A & B data added")
  }
  
  data_qc <- dataset %>% 
    # Basic quality control; only physically possible values (and real numbers) are kept
    filter_at(
      # Selecting the columns that start with 'pm25'
      vars(starts_with("pm25")),
      # Filtering said columns such that only values 0:2000 are kept
      all_vars(between(., 0, 2000))
    ) %>% 
    filter(
      # Filtering temperature for -40:185
      between(temperature, -40, 185),
      # Filtering humidity for 0:100
      between(humidity, 0, 100)
    )
  
  return(data_qc)
}
```

```{r function_epa}
apply_epa <- function(dataset, by_day = TRUE, by_hour = FALSE, epa_percent = 75){
  
  if(by_day == FALSE & by_hour == FALSE){
    stop("INPUT ERROR: Please set `by_day` and/or `by_hour` to TRUE.")
  }
  if(by_day == TRUE & by_hour == FALSE){
    print("Grouping by date (24 hour averages, by day) [default]")
    groupings_drop <- vars(site_id, date, date_hour)
    groupings <- vars(site_id, date)
    time_unit <- 24
  }
  if(by_day == TRUE & by_hour == TRUE){
    print("Grouping by date and hour (1 hour averages, by day)")
    dataset <- dataset %>% 
      mutate(minute = minute(datetime))
    groupings_drop <- vars(site_id, date, date_hour, minute)
    groupings <- vars(site_id, date, date_hour)
    time_unit <- 60/2
  }
  if(by_day == FALSE & by_hour == TRUE){
    print("Grouping by hour (1 hour averages)")
    dataset <- dataset %>% 
      mutate(
        hour = hour(datetime),
        minute = minute(datetime)
      )
    groupings_drop <- vars(site_id, hour, minute)
    groupings <- vars(site_id, hour)
    time_unit <- 60/2
  }
  
  # Calculating the minimum number of data points required to be included in the set
  count_to_drop <- ceiling(time_unit*(epa_percent/100))
  
  # Creating a data frame of groups to be removed due to low data quantity
  drop_quantity <- dataset %>% 
    group_by_at(groupings_drop) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    group_by_at(groupings) %>% 
    count() %>% 
    filter(n < count_to_drop)
  
  print("Values to be dropped via an anti-join due to low data quantity:")
  print(drop_quantity)
  
  drop_ab <- dataset %>% 
    group_by(site_id, date) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    mutate(
      # Difference between A & B sensors
      diff = pm25_cf1_A-pm25_cf1_B,
      # Percentage difference between A & B sensors
      per_diff = 100*(abs(pm25_cf1_A-pm25_cf1_B))/((pm25_cf1_A+pm25_cf1_B)/2),
      drop = case_when(
        # Will drop the following based on EPA recommendations
        abs(diff) >= 5 & abs(per_diff) >= 62 ~ TRUE,
        # Fills all other values (the ones to be kept) with 'false'
        TRUE ~ FALSE
        )
      ) %>% 
    filter(drop == TRUE) %>% 
    select(site_id, date)
  
  print("Days (by sensor) to be dropped via an anti-join due to A & B sensor disagreement:")
  print(drop_ab)
  
  dataset %>% 
    anti_join(drop_quantity) %>% 
    anti_join(drop_ab) %>% 
    group_by_at(groupings) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    rowwise() %>% 
    mutate(
      # US-wide correction factor published in 2020
      epa_2020 = 0.524*pm25_cf1 - 0.0852*humidity + 5.72,
      # US-wide correction factor published in late 2020
      epa_2021 = case_when(
        pm25_cf1 <= 343 ~ 0.52*pm25_cf1 - 0.086*humidity + 5.75,
        pm25_cf1 > 343 ~ 0.46*pm25_cf1 + (3.93*10^(-4))*(pm25_cf1^2) +2.97
      ),
      # US-wide correction factor published in late 2020 using CF=ATM values
      epa_atm = case_when(
        pm25_atm < 50 ~ 0.25*pm25_atm - 0.086*humidity + 5.75,
        pm25_atm >= 50 & pm25_atm < 229 ~ 0.786*pm25_atm - 0.086*humidity + 5.75,
        pm25_atm > 229 ~ 0.69*pm25_atm + (8.84*10^-4)*(pm25_atm^2) + 2.97
      )
    ) %>% 
    # Setting negative values to NA
    mutate_at(vars(epa_2020, epa_2021, epa_atm), ~replace(., which(.<0), NA))
    # # Dropping negative values
    # filter_at(vars(epa_2020, epa_2021, epa_atm), all_vars(. >= 0))
}
```


```{r function_lrapa}
apply_lrapa <- function(dataset, by_day = TRUE, by_hour = FALSE){
  
  if(by_day == FALSE & by_hour == FALSE){
    stop("INPUT ERROR: Please set `by_day` and/or `by_hour` to TRUE.")
  }
  if(by_day == TRUE & by_hour == FALSE){
    print("Grouping by date (24 hour averages, by day) [DEFAULT]")
    groupings <- vars(site_id, date)
  }
  if(by_day == TRUE & by_hour == TRUE){
    print("Grouping by date and hour (1 hour averages, by day)")
    groupings <- vars(site_id, date, date_hour)
  }
  if(by_day == FALSE & by_hour == TRUE){
    print("Grouping by hour (1 hour averages)")
    groupings <- vars(site_id, hour)
    dataset <- dataset %>% 
      mutate(hour = hour(datetime))
  }
  
  dataset %>% 
    group_by_at(groupings) %>% 
    summarize_if(is.numeric, mean, na.rm = TRUE) %>% 
    rowwise() %>% 
    mutate(
      lrapa = case_when(pm25_cf1 <= 65 ~ 0.5 * pm25_atm - 0.66)
      ) %>% 
    # Setting negative values to NA
    mutate_at(vars(lrapa), ~replace(., which(.<0), NA))
    # # Dropping negative values
    # filter(lrapa >= 0)
}
```

```{r function_corrections}
apply_corrections <- function(data, daily, hourly, epa = 75){
  epa <- data %>% 
    apply_epa(by_day = daily, by_hour = hourly, epa_percent = epa)
  print("EPA corrections applied")
  
  lrapa <- data %>% 
    apply_lrapa(by_day = daily, by_hour = hourly)
  print("LRAPA corrections applied")
  
  df_corr <- epa %>% 
    full_join(lrapa)
  print("Data frame of corrected values created")
  return(df_corr)
}
```

```{r function_tag_dates}
apply_date_tags <- function(dataset,
                        starts = input_date_starts, ends = input_date_ends, tags = input_date_tags,
                        date_stamp = "17 Jan 1999"){
  
  starts <- as.Date(starts)
  ends <- as.Date(ends)
  tags <- factor(tags)
  date_format <- stamp_date(date_stamp)
  
  data_temp <- data.frame(starts, ends, tags) %>% 
    arrange(starts) %>% 
    mutate(
      start_stamp = date_format(starts),
      end_stamp = date_format(ends),
      date_tag = fct_inorder(paste0(tags, "\n(", start_stamp, " - ", end_stamp, ")"))
    ) %>% 
    pivot_longer(cols = c(starts, ends), values_to = "date") %>% 
    group_by(date_tag) %>% 
    complete(date = full_seq(date, 1)) %>% 
    select(!c(name, tags, start_stamp, end_stamp))
  
  dataset %>% 
    left_join(data_temp) %>% 
    drop_na(date_tag)
}
```

```{r function_tag_hours}
apply_hour_tags <- function(dataset, starts = input_hour_starts, tags = input_hour_tags){
  tags <- factor(tags)
  
  hours_in_day <- data.frame(starts = 0:23)
  
  data_temp <- data.frame(starts, tags) %>% 
    mutate(
      ends = lead(starts - 1),
      ends = replace_na(ends, starts[1]-1),
      tags = paste0(tags, "\n(", formatC(starts, width=2, flag=0), ":00-", formatC(ends, width=2, flag=0), ":59)")
    ) %>% 
    arrange(starts) %>% 
    mutate(hour_tag = fct_inorder(tags)) %>%
    complete(starts = full_seq(starts, 1)) %>%
    right_join(hours_in_day) %>%
    rename(hour = starts) %>%
    fill(hour_tag) %>%
    select(!c(tags, ends))# %>%
    # HR_CHANGES
    # mutate(hour = hms::as_hms(hour*60*60))
  # HR_CHANGES
  
  if("hour" %in% colnames(dataset) == FALSE){
    dataset <- dataset %>% 
      mutate(hour = hour(date_hour))
    #   # HR_CHANGES
    #   mutate(
    #     hour = hour(date_hour),
    #     hour = hms::as_hms(hour*60*60)
    #   )
    # # HR_CHANGES
  }
  
  dataset %>% 
    left_join(data_temp)
}
```

```{r function_applying}
applying_functions <- function(dataframe, group_day, group_hour, tag_dates = run_date_grouping, tag_hours = run_hour_grouping){
  
  # Applying correction factors
  new_df <- dataframe %>%
    apply_corrections(daily = group_day, hourly = group_hour)
  print("Correction factors applied.")
  
  # Tagging by date
  if(tag_dates == TRUE & group_day == TRUE){
    # tagged_days <- dataframe %>% 
    #   apply_date_tags() %>% 
    #   select(date, date_tag)
    tagged_days <- dataframe %>% 
      select(date) %>% 
      distinct() %>% 
      apply_date_tags() %>% 
      select(date, date_tag)
    
    new_df <- new_df %>% left_join(tagged_days)
    print("Data now tagged by provided date groupings.")
  } else {
    print("Date groups not applied.")
  }
  
  # Tagging by hour
  if(group_hour == TRUE & tag_hours == TRUE){
    # tagged_hours <- dataframe %>% 
    #   apply_hour_tags() %>% 
    #   select(hour, hour_tag)
    tagged_hours <- dataframe %>% 
      select(date_hour) %>% 
      distinct() %>% 
      apply_hour_tags() %>% 
      select(hour, hour_tag) %>% 
      distinct()
    
    if("hour" %in% colnames(new_df) == FALSE){
      new_df <- new_df %>% 
        mutate(hour = hour(date_hour))
    }
    
    new_df <- new_df %>% left_join(tagged_hours)
    print("Data now tagged by provided hour groupings.")
    
  } else {
    print("Hour groups not applied.")
  }
  
  # Returning the adjusted dataframe
  return(new_df)
}
```

```{r data_applying}
data_hourly <- applying_functions(data_pm25, group_day = TRUE, group_hour = TRUE)
data_daily <- applying_functions(data_pm25, group_day = TRUE, group_hour = FALSE)
data_diurnal <- applying_functions(data_pm25, group_day = FALSE, group_hour = TRUE)
```

```{r eclean_applying, eval=FALSE}
remove(apply_corrections, applying_functions, apply_epa, apply_lrapa, apply_hour_tags, apply_date_tags)
```


```{r viz_function_single_heatmap,eval=FALSE}
heatmap_single <- function(dataset, site_of_interest, variable_of_interest,
                           digits = 2, location_data = data_meta){
  
  if(deparse(substitute(variable_of_interest)) %in% colnames(dataset) == FALSE){
    dataset %>%
      slice(1) %>%
      ungroup() %>%
      select(!intersect(c("hour", "minute"), colnames(.))) %>%
      select_if(is.numeric) %>%
      colnames() %>%
      print()
    stop("ERROR: Inputted variable of interest is not in the provided data set. Execution halted. Valid inputs are listed above")
  }
  
  temp_loc <- location_data %>% 
    select(site_id, label)
  
  temp_df <- dataset %>% 
    ungroup() %>% 
    # Adding labels to the data set
    left_join(temp_loc) %>% 
    # Filtering data set based on inputted site of interest
    filter(str_detect(label, site_of_interest)) %>% 
    # Removing empty values from variable of interest (otherwise is grey when mapping)
    drop_na({{variable_of_interest}}) %>% 
    # Removing duplicate rows
    distinct()
  
  # Verification that only one monitor is selected. Execution will halt if 0 or >1 are detected
  if(length(unique(temp_df$label)) == 0){
    stop("ERROR: No monitors selected. Please verify that a distinct label was provided. Capitalization matters.")
  }
  if(length(unique(temp_df$label)) > 1){
    print("Matching locations from meta data:")
    temp_loc %>% filter(str_detect(label, site_of_interest)) %>% distinct() %>% pull(label) %>% print()
    print("Matching locations that contain values of interest:")
    temp_df %>% pull(label) %>% unique() %>% print()
    stop("ERROR: More than one site selected. Please use a more precise string argument; matching values are listed above.")
  }
  
  
  lab_title <- expression("Heatmap of PM"[2.5]*" values across time")
  lab_subtitle <- paste0("Data from PurpleAir. Monitor selected: \"", unique(temp_df$label),
                        "\". Data plotted: ", deparse(substitute(variable_of_interest)))
  lab_fill <- expression(paste("Average PM"[2.5]*" (", mu, "g/m"^3*"):"))
  fill_colors <- scale_fill_viridis(option = "plasma", limits = c(0, NA))
  
  if(str_detect(deparse(substitute(variable_of_interest)), "temp") == TRUE){
    lab_title <- paste("Heatmap of internal temperature values across time")
    lab_fill <- "Internal temperature (\u00B0F):"
    fill_colors <- scale_fill_viridis(option = "cividis", begin = 0.15)
    print("Temperature detected as variable of interest; adjusting labels accordingly")
  }
  if(str_detect(deparse(substitute(variable_of_interest)), "humid") == TRUE |
     deparse(substitute(variable_of_interest)) == "rh"){
    lab_title <- paste("Heatmap of RH values across time")
    lab_fill <- "Relative humidity (%):"
    fill_colors <- scale_fill_viridis(option = "mako", direction = -1, limits = c(0, 100), end = 0.9)
    print("RH detected as variable of interest; adjusting labels accordingly")
  }
  
  # Allows for ending 0 when rounding
  label_digits <- paste0("%.", deparse(substitute(digits)), "f")
  
  # Plotting data
  temp_df %>% 
    ggplot(aes(x = date,
               y = hour,
               fill = {{variable_of_interest}},
               label = as.character(sprintf(label_digits, round({{variable_of_interest}}, digits = digits)))
    )) +
    geom_tile() +
    fill_colors +
    geom_text() +
    # Setting scale breaks such that 0:23 will always display, regardless of data availability
    scale_y_continuous(trans = "reverse", breaks = 0:23, limits = c(24,-1)) +
    scale_x_date(breaks = "1 day", date_labels = "%d %b %Y") +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      panel.grid = element_blank(),
      axis.title.x = element_blank()
    ) +
    labs(
      title = lab_title,
      subtitle = lab_subtitle,
      fill = lab_fill,
      y = "Hour of the day"
    )
}
```


## EPA viz
```{r,eval=FALSE}
# id_star_sel <- data_meta %>% 
#   filter(str_detect(label, "PSU STAR LAB SEL")) %>% 
#   pull(site_id)
# 
# data_pa_star <- data_hourly %>% 
#   filter(site_id == id_star_sel)
# 
# data_star_sel <- data_pa_star %>% 
data_star_sel <- data_pa_hourly %>% 
  full_join(data_deq) %>% 
  select(date, date_hour, pm25_atm, pm25_cf1, epa_2020, epa_2021, lrapa, pm25_deq, date_tag, hour_tag) %>% 
  drop_na(date_tag)

data_star_sel %>% 
  mutate(across(where(is.numeric), ~.-pm25_deq)) %>% 
  pivot_longer(cols = where(is.numeric)) %>% 
  filter(name %in% c("epa_2020", "epa_2021", "lrapa", "pm25_deq")) %>% 
  ggplot(aes(date_hour, value, color = name)) +
  #facet_wrap(~date_tag, scales = "free") +
  #facet_grid(hour_tag~date_tag, scales = "free") +
  #facet_wrap(hour_tag~date_tag, scales = "free") +
  geom_line() +
  theme(legend.position = "bottom")
```


## WRANGLE
```{r manual_apply, eval=FALSE}
data_pa_hourly <- data_pa %>% 
  apply_corrections(daily = TRUE, hourly = TRUE) %>% 
  apply_hour_tags() %>% 
  apply_date_tags()

data_pa_daily <- data_pa %>% 
  apply_corrections(daily = TRUE, hourly = FALSE) %>% 
  apply_date_tags()
```

```{r mapping_test, eval=FALSE}
data_pa_hourly %>%
  map_q(value = pm25_atm, location_data = data_pa_meta, grouping_var = hour_tag)

long_set <- data_pa_hourly %>% 
  pivot_longer(cols = c(pm25_cf1, epa_2020, epa_2021, epa_atm, lrapa, pm25_atm),
               names_to = "corr",
               values_to = "pm25") %>% 
  mutate(
    corr = fct_inorder(corr),
    source = fct_collapse(corr,
      PA = c("pm25_cf1", "pm25_atm"),
      EPA = c("epa_2020", "epa_2021", "epa_atm"),
      LRAPA = "lrapa"
    )
  )

long_set %>% 
  drop_na(date_tag) %>% 
  ggplot(aes(date_hour, pm25, color = corr, linetype = source)) +
  facet_grid(cols=vars(date_tag), scales="free") +
  geom_line() +
  theme(legend.position = "bottom")
  

  
long_set %>% 
  drop_na(date_tag) %>% 
  #ggplot(aes(source, value, color = name)) +
  ggplot(aes(corr, pm25, color = source)) +
  #facet_wrap(~date_tag, scales = "free") +
  facet_grid(cols=vars(date_tag), scales="free") +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75), linetype = "dotted") +
  geom_violin(draw_quantiles = 0.5, fill = "transparent") +
  stat_summary(fun.y = mean, geom ="point", color = "red") +
  theme(legend.position = "bottom")

long_set %>% 
  filter(str_detect(date_tag, "Before|After")) %>% 
  mutate(wday = lubridate::wday(date, label=TRUE),
         blah=hms(format(date_hour, format="%H:%M:%S"))) %>% 
  select(date_hour, blah, wday, hour, hour_tag, corr, pm25, source) %>% 
  ggplot(aes(x=blah, y=pm25, color=corr)) +
  scale_x_time() +
  facet_grid(cols=vars(wday), rows=vars(source)) +
  geom_line()

data_pa_hourly %>% 
  drop_na(date_tag) %>% 
  #filter(str_detect(date_tag, "Before")) %>% 
  #filter(str_detect(date_tag, "Before|After")) %>% 
  mutate(wday=lubridate::wday(date,label=TRUE)) %>% 
  group_by(site_id,date_tag,hour,wday) %>% 
  summarize_if(is.numeric, mean, na.rm=TRUE) %>% 
  ggplot(aes(x = hour, y = epa_2021,color=date_tag)) +
  #facet_grid(cols = vars(wday)) +
  facet_grid(date_tag~wday, scales="free_y") +
  geom_line() +
  theme(legend.position="bottom")
```


## 27 Jun archiving

```{r viz_function_map}
# FUNCTION
# Required inputs: pm_data (df), value (column of PM2.5 data w/in df to map), location_data (lat/long data to be joined to df; default: data_meta)
# Optional inputs: grouping variables (1 or 2) w/ respective custom exclusions; filter for indoor/outdoor data
# Other customization for map: type (stamen), zoom, tint & color, point size, color scale (virids)

map_q <- function(pm_data, value, location_data = data_meta,
                  grouping_var = NULL, exclude = NULL,
                  grouping_var_2 = NULL, exclude_2 = NULL,
                  outside = include_outside, inside = include_inside,
                  label = c(""),
                  maptype = "toner-lite", zoom = 11, tint = 0.5, tint_color = "black",
                  point_size = 3, viridis = "viridis"){
  
  # Warning message and halting execution if required input is missing.
  if (missing(value) == TRUE) {
    stop ("ERROR in argument 'value': Missing input, with no default. Execution haulted. Please input a valid PM2.5 variable (e.g. epa_2021).")
  }
  
  # Warning message and halting execution if inputeded data does not have more than one unique site_id (map will bug)
  if (length(unique(pm_data$site_id)) == 1) {
    stop("ERROR: Insufficient data to create a map. Provide a data set with more than one site.")
  }
  
  input_labels <- paste0("(", paste(label, collapse = ")|("), ")")
  
  # Wrangling based on provided inputs
  data_temp <- pm_data %>% 
    ungroup() %>% 
    # Grouping by provided variables, as well as site_id
    group_by_at(vars(site_id, {{grouping_var}}, {{grouping_var_2}})) %>% 
    # Calculating means by said grouping variables
    summarize(mean = mean({{value}}, na.rm = TRUE)) %>% 
    drop_na(mean) %>% 
    # Adding location data to get lat & lon
    left_join(location_data) %>% 
    # Selecting desired labels, if provided
    filter(str_detect(label, input_labels))
  
  # Feedback message
  print("Data now grouped and averaged. Location data added.")
  
  # Custom filtering: exclusions for input categories
  if (is.null(exclude) == FALSE) {
    to_exclude <- paste(exclude, collapse = "|")
    data_temp <- data_temp %>% 
      filter(!str_detect({{grouping_var}}, to_exclude))
    print(paste("Excluded", exclude, "from", deparse(substitute(grouping_var))))
  }
  if (is.null(exclude_2) == FALSE) {
    to_exclude_2 <- paste(exclude_2, collapse = "|")
    data_temp <- data_temp %>% 
      filter(!str_detect({{grouping_var_2}}, to_exclude_2))
    print(paste("Excluded", exclude_2, "from", deparse(substitute(grouping_var_2))))
  }
  
  # Default shapes for inside/outside
  shapes_inout <- c("outside" = 21, "inside" = 23)
  
  # Custom filtering: exclusions for inside/outside
  # Will also override shape arguments to prevent excluded category from showing in the legend
  if (outside == FALSE) {
    data_temp <- data_temp %>% 
      filter(DEVICE_LOCATIONTYPE != "outside")
    print("Outdoor data excluded")
    shapes_inout <- c("inside" = 23)
  }
  if (inside == FALSE) {
    data_temp <- data_temp %>% 
      filter(DEVICE_LOCATIONTYPE != "inside")
    print("Indoor data excluded")
    shapes_inout <- c("outside" = 21)
  }
  
  
  # Labels for the plot
  lab_title <- expression("PM"[2.5]*" values")
  lab_subtitle <- paste("Data from PurpleAir. Data plotted:", deparse(substitute(value)))
  lab_pm <- expression(paste("Average PM"[2.5]*" (", mu, "g/m"^3*"):"))
  
  # Base plot
  plot <- qmplot(data = data_temp, x = longitude, y = latitude,
         geom = "blank", maptype = maptype, zoom = zoom, darken = c(tint, tint_color)) +
    facet_wrap(vars({{grouping_var}})) +
    geom_point(
      aes(fill = mean, shape = DEVICE_LOCATIONTYPE),
      color = "white",
      alpha = 0.8,
      size = point_size
    ) +
    scale_fill_viridis(
      option = {{viridis}},
      direction = -1,
      end = 0.85,
      limits = c(0, NA)
    ) +
    theme_void() +
    scale_shape_manual(values = shapes_inout) +
    theme(
      legend.position = "bottom",
      legend.box = "vertical"
    ) + 
    guides(shape = guide_legend(override.aes = list(fill="black"))) +
    labs(
      title = lab_title,
      subtitle = lab_subtitle,
      fill = lab_pm,
      shape = "Monitor location:",
      caption = "Data not grouped."
    )
  
  # Feedback message
  print("Base plot created.")
  
  ## Faceting by grouping variable(s) and applying an appropriate caption to reflect the grouping
  # Facet wrap if 1 grouping variable provided
  if (deparse(substitute(grouping_var)) != "NULL" & deparse(substitute(grouping_var_2)) == "NULL") {
    plot <- plot +
      facet_wrap(vars({{grouping_var}})) +
      labs(
        caption = paste(
          "Data grouped by",
          (colnames(pm_data %>% select({{grouping_var}})))[1]
        )
      )
    # Feedback message
    print(paste("Plot now faceted by", deparse(substitute(grouping_var))))
  }
  # Facet grid if 2 grouping variables provided
  if (deparse(substitute(grouping_var)) != "NULL" & deparse(substitute(grouping_var_2)) != "NULL") {
    plot <- plot +
      facet_grid(
      formula(paste(
        vars({{grouping_var_2}}),
        "~",
        vars({{grouping_var}})
      ))) +
      labs(
        caption = paste(
          "Data grouped by",
          deparse(substitute(grouping_var)),
          "and",
          deparse(substitute(grouping_var_2))
          )
      )
    # Feedback message
    print(paste("Plot now faceted by",
                deparse(substitute(grouping_var)),
                "and",
                deparse(substitute(grouping_var_2))
                ))
  }
  
  print("Final plot created.")
  
  # Returning the final plot
  plot
}
```

```{r test_map, eval=FALSE}
map_q(data_hourly, value = epa_2021, grouping_var = hour_tag)

data_hourly %>% 
  column_dt("hour") %>% 
  mutate(hour = as.factor(hour)) %>% 
  map_q(value = epa_2021, grouping_var = hour, grouping_var_2 = date_tag, inside=FALSE)

map_q(data_daily, value = epa_2020, grouping_var = date_tag, inside = FALSE)

map_q(data_daily, value = lrapa, grouping_var = date_tag, exclude = "Fire")

map_q(data_hourly, value = pm25_atm, grouping_var = hour_tag, exclude = "Afternoon", point_size = 5,
      maptype = "terrain", tint = 0.3, tint_color = "white", viridis = "magma")
```

```{r function_units}
settings_units <- function(dataset, var_qt, cap_color, digits, lab_title = "Graph of",
                           lab_fill = "Units", lab_unit = "units") {
  
  # Defaults
  lab_title_val <- var_qt
  # y_line <- NULL
  # Color scale will default set to start at 0, regardless of minimum in data
  fill_colors <- scale_fill_viridis(option = "plasma", limits = c(0, NA), na.value = cap_color)
  
  if (str_detect(var_qt, "pm") == TRUE) {
    lab_title_val <- "Particulate Matter (PM)"
    # lab_unit <- expression(paste(mu, "g/m"^3))
    #lab_unit <- expression(mu*"g/m"^3)
    # lab_unit <- "Âµg/m^3"
    lab_unit <- '*mu*"g/m"^3*'
    
    if (str_detect(var_qt, "(1.0)|(01)|(1$)|(1\\D)") == TRUE) {
      pm_val <- 1.0
      print("PM 1.0 detected")
    } else if (str_detect(var_qt, "(25)|(2.5)") == TRUE) {
      pm_val <- 2.5
      print("PM 2.5 detected")
    } else if (str_detect(var_qt, "(10)") == TRUE) {
      pm_val <- 10
      print("PM 10 detected")
    } else {
      pm_val <- NULL
      print("PM unit undetermined")
    }
    lab_fill <- parse(text = paste0('PM[', pm_val, ']~"("', lab_unit,'")"'))
    lab_unit <- "units"
    # y_line <- geom_hline(yintercept = 0, linetype = "longdash", alpha = 0.5)
    #bquote(PM[.(pm_val)]~"("*mu*"g/"*m^3*")")
  }
  
  # Adjusting color scale and labels if the variable of interest is internal temperature
  if (str_detect(var_qt, "temp") == TRUE) {
    lab_title_val <- "internal temperature"
    fill_colors <- scale_fill_viridis(option = "cividis", begin = 0.15, na.value = cap_color)
    print("Temperature detected as variable of interest; adjusting labels accordingly")
    lab_unit <- "\u00B0F"
    
    if (str_detect(var_qt, "_c") == TRUE) {
      lab_unit <- "\u00B0C"
      print("Temperature detected to be in Celsius")
    } else { print("Temperature assumed to be in Fahrenheit") }
    
    lab_fill <- paste0("Internal temperature (", lab_unit, ")")
  }
  
  # Adjusting color scale and labels if the variable of interest is RH
  if (str_detect(var_qt, "((H|h)umid)|(rh)|(RH)") == TRUE) {
    lab_title_val <- "humidity"
    lab_unit <- "%"
    lab_fill <- paste0("Relative humidity (", lab_unit, ")")
    # y_line <- geom_hline(yintercept = c(0,100), linetype = "longdash", alpha = 0.5)
    fill_colors <- scale_fill_viridis(option = "mako", direction = -1, limits = c(0, 100), end = 0.9, na.value = cap_color)
    print("RH detected as variable of interest; adjusting labels accordingly")
  }
  
  # Getting min and max values from the data set
  val_min <- dataset %>% select(var_qt) %>% min(na.rm = TRUE)
  val_max <- dataset %>% select(var_qt) %>% max(na.rm = TRUE)
  
  lab_subtitle <- paste0("Variable plotted: ",
                         var_qt,
                         ", with a reported range of ",
                         round(val_min, digits = digits),
                         " to ",
                         round(val_max, digits = digits),
                         " ", lab_unit, ".")
  
  return(list(
    # y_line = y_line,
    lab_title = lab_title,
    lab_title_val = lab_title_val,
    lab_subtitle = lab_subtitle,
    lab_fill = lab_fill,
    fill_colors = fill_colors
  ))
}
```


```{r viz_function_heatmap}
heatmap_cross <- function(dataset, variable_of_interest, drop_incomplete = FALSE,
                          cap_value = NA, cap_color = red,
                          location_data = data_meta, digits = 2,
                          start_date = input_startdate, end_date = input_enddate){
  
  # Dropping NA values from the variable of interest
  # Will appear as gaps if viewing the complete viz, rather than gray
  dataset <- dataset %>% 
    drop_na({{variable_of_interest}})
  
  variable_of_interest_qt <- deparse(substitute(variable_of_interest))
  
  # If monitors with missing values for any time stamp are to be dropped
  if (drop_incomplete == TRUE) {
    # Number of values expected for a complete set
    complete_num <- (dataset %>% 
                       ungroup() %>% 
                       count(site_id) %>% 
                       arrange(desc(n)) %>% 
                       pull(n))[1]
    
    # List of monitors with incomplete sets
    to_drop <- dataset %>% 
      ungroup() %>% 
      count(site_id) %>% 
      filter(n != complete_num) %>% 
      pull(site_id)
    
    # Feedback
    print("Monitors with incomplete temporal data that will be dropped:")
    print(paste(to_drop))
    
    # Removing incomplete monitors
    dataset <- dataset %>% 
      filter(!site_id %in% to_drop)
    
  } else { print("All monitors will be plotted.") }
  
  # Adding quotation marks
  cap_color <- deparse(substitute(cap_color)) %>%
    str_replace_all("\\\"", "") # Removing extra quotation marks if already provided
  
  # Location data
  temp_loc <- location_data %>% 
    # Arranging such that northern-most monitors will be on top
    mutate(label = fct_reorder(as.factor(label), desc(latitude))) %>% 
    # Selecting only variables of interest to save space
    select(site_id, label, DEVICE_LOCATIONTYPE)
  
  unit_results <- settings_units(dataset = dataset, var = variable_of_interest_qt, cap_color = cap_color,
                                 lab_title = "Heatmap of")
  
  lab_title <- unit_results$lab_title
  lab_title_val <- unit_results$lab_title_val
  lab_subtitle <- unit_results$lab_subtitle
  lab_fill <- unit_results$lab_fill
  fill_colors <- unit_results$fill_colors
  
  cap_guide <- guides(fill = guide_colorbar(order = 1, barwidth = 10),
                      color = "none")

  # If manually applying a max filter value
  if (is.na(cap_value) == FALSE) {
    # Getting number of rows at or above the cap
    nrow_hi <- dataset %>%
      filter({{variable_of_interest}} >= cap_value) %>%
      nrow()

    if ((nrow_hi > 0) == TRUE) {
      # Replacing the values above the set max to be NA so that they will be colored differently on the map
      dataset <- dataset %>%
        mutate_at(vars({{variable_of_interest}}), ~replace(., which(.>={{cap_value}}), NA))

      # Updated lab caption to include the filter
      lab_subtitle <- paste0("Color scale manually capped at ",
                             cap_value, " units; all higher values colored ", cap_color,
                             ".\n", lab_subtitle)

      # Feedback
      print(paste("Values greater than or equal to",
                  {{cap_value}},
                  "in",
                  variable_of_interest_qt,
                  "will be colored",
                  cap_color))

      cap_guide <- guides(fill = guide_colorbar(order = 1, barwidth = 10),
                          color = guide_legend(
                            title = paste0(cap_value, "+"),
                            order = 2,
                            title.position = "bottom",
                            title.theme = element_text(size = 10),
                            override.aes = list(color = cap_color, fill = cap_color)
                          ))
    } else {
      print(paste0("No values greater than or equal to ",
                   {{cap_value}},
                   " found in ",
                   variable_of_interest_qt,
                   "; color cap will not be applied."))
    }
  }
  
  scale_results <- settings_dt_scale(dataset = dataset, start_date = start_date, end_date = end_date)
  
  dataset <- scale_results$dataset
  lab_title_sub <- scale_results$lab_title_sub
  x_angle <- scale_results$x_angle
  x_scale <- scale_results$x_scale
  lab_caption <- scale_results$lab_caption
  
  lab_caption <- paste0(lab_caption, "\nMonitors are arranged north to south in their respective groups.")
  
  
  dataset %>% 
    distinct() %>% 
    left_join(temp_loc) %>% 
    ggplot(aes(
      x = timestamp,
      y = label,
      color = "",
      fill = {{variable_of_interest}}
    )) +
    facet_grid(DEVICE_LOCATIONTYPE~., scales = "free_y", space = "free_y") +
    geom_tile() +
    fill_colors + 
    scale_y_discrete(limits = rev) + 
    theme_minimal() +
    theme(
      legend.position = "bottom",
      panel.grid = element_blank(),
      panel.border = element_blank(),
      axis.text.x = element_text(angle = x_angle, hjust = 1),
      axis.title = element_blank(),
      axis.ticks.x = element_line()
    ) + 
    labs(
      title = paste(lab_title, lab_title_val, lab_title_sub),
      subtitle = lab_subtitle,
      fill = lab_fill,
      caption = lab_caption
    ) +
    x_scale + 
    scale_color_manual(values = "transparent") +
    cap_guide
}
```