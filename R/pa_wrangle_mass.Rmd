---
title: "pa_wrangle_mass"
author: "Gillian McGinnis"
date: "1/11/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #dplyr, etc
library(lubridate) #better time/date manipulation
```


```{r data}
#do not run this often. large dataframes!
my_file_paths <- list.files(path = "data/raw", pattern = ".+\\(*(outside*)\\w+\\)", full.names = TRUE)

#my_file_paths <- list.files(path="data/raw", pattern=".+(E )",full.names=TRUE) #smaller subset
#my_file_paths <- list.files(path="data/raw", pattern="SE",full.names=TRUE) #smaller subset

#pray that R doesn't crash when you run this
raw_data <- my_file_paths %>%
  set_names() %>%
  map_dfr(~read_csv(.x, col_types = cols(source = col_character(),
                                         created_at = col_character(),
                                         .default = col_double())), .id="source") %>%
  mutate(source = str_replace(source, ".\\w+\\/\\w+\\/", "")) #removes filepath name
```


```{r tidying}
df <- raw_data %>%
  #drop_na(`PM2.5_CF1_ug/m3`) %>% #removes empty values for stat of interest
  mutate(created_at = as_datetime(created_at), #converting from character to date time format; tz is in UTC
         date = date(created_at), #picking out just the date
         #time = strftime(created_at, format="%H:%M:%S"), # old way of picking time; outputs char
         time = hms::as_hms(created_at), #picking out just the time
         time_est = time) %>% #currently working on rounding out the seconds but for now it stands as is
  mutate(coords = str_extract(source, "([0-9])\\w+\\.([0-9])\\w+\\s\\-([0-9])\\w+\\.([0-9])\\w+"), #grabbing coord data
         lat = str_extract(coords, "\\d+\\.\\d+\\s"), #latitude (north)
         lat = str_trim(lat, side = "right"), #removing extra whitespace
         lat = as.numeric(lat), #converting to numeric from character
         long = str_extract(coords, "\\-\\d+\\.\\d+"), #longitude (negative here, so west)
         long = as.numeric(long), #converting to numeric from character
         loc_tag = str_extract(source, "^[^\\(]+"), #grabbing location tag
         loc_tag = str_trim(loc_tag, side = "right")) %>% #removing extra whitespace
  mutate(hour = hour(created_at),
         hour_round = hour(round_date(created_at, unit="hour")),
         year = year(created_at),
         month = month(created_at, label=TRUE),
         day = day(created_at))


unique_locations <- unique(df$loc_tag) #creates list of unique locations for quick reference
unique_vars <- names(df) #creates list of columns for quick reference
```

```{r summary dfs}
vars <- names(df)[4:20] #check to make sure these include all vars of interest. Uninteresting ones can always be dropped later.

#faster to process than the above wrangling but still takes time

daily_df <- df %>%
  group_by(loc_tag, date, lat, long) %>%
  summarize_at(vars,
               mean,
               na.rm=TRUE) %>%
  mutate(month = month(date, label=TRUE),
         day = day(date))

hourly_df <- df %>%
  group_by(loc_tag, date, hour, lat, long) %>%
  summarize_at(vars,
               mean,
               na.rm=TRUE) %>%
  mutate(month = month(date, label=TRUE),
         day = day(date))
```

```{r saving large dfs}
#do not run this often. large dataframes!
write.csv(raw_data, "data/wrangled/raw_df.csv", row.names=TRUE)
write.csv(df, "data/wrangled/wrangled_df.csv", row.names=TRUE)
```

```{r saving summary dfs}
write.csv(hourly_df,"data/wrangled/hourly_df.csv", row.names = TRUE)
write.csv(daily_df, "data/wrangled/daily_df.csv", row.names=TRUE)
```